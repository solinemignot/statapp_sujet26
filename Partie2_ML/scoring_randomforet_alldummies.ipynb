{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "# Pour le ML\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, learning_curve, validation_curve, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Charger le jeu de données\n",
    "path = \"/home/onyxia/work/statapp_sujet26/\"\n",
    "\n",
    "file_name1 = \"dataset_complet_avec_dummies_part_1.csv\"\n",
    "file_name2 = \"dataset_complet_avec_dummies_part_2.csv\"\n",
    "file_name3 = \"dataset_complet_avec_dummies_part_3.csv\"\n",
    "file_name4 = \"dataset_complet_avec_dummies_part_4.csv\"\n",
    "df1 = pd.read_csv(path+file_name1, sep=',',low_memory=False)\n",
    "df2 = pd.read_csv(path+file_name2, sep=',',low_memory=False)\n",
    "df3 = pd.read_csv(path+file_name2, sep=',',low_memory=False)\n",
    "df4 = pd.read_csv(path+file_name2, sep=',',low_memory=False)\n",
    "df = pd.concat([df1,df2,df3,df4])\n",
    "\n",
    "\n",
    "df['grav'] = df['grav'].replace({1:0,2:0,3:1,4:1})\n",
    "\n",
    "y = df['grav']\n",
    "X = df.drop(columns=['grav'])\n",
    "features = X.columns\n",
    "\n",
    "\n",
    "# Diviser les données en ensembles de formation et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Normaliser les données\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Définir les hyperparamètres à tester\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [350, 400, 450],\n",
    "    'max_depth': [30, 35, 40],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialiser le modèle Random Forest\n",
    "model_rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialiser StratifiedKFold\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialiser GridSearchCV avec le modèle, la grille de paramètres et StratifiedKFold\n",
    "grid_search_rf = GridSearchCV(estimator=model_rf, param_grid=param_grid_rf, cv=k_fold, scoring='f1')\n",
    "\n",
    "# Exécuter la recherche sur la grille\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Afficher les meilleurs paramètres et le meilleur score\n",
    "print(\"Meilleurs Paramètres:\", grid_search_rf.best_params_)\n",
    "print(\"Meilleur Score:\", grid_search_rf.best_score_)\n",
    "\n",
    "model_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "\n",
    "###GRID SEARCH POUR F1###\n",
    "grid_search_f1 = GridSearchCV(estimator=model_rf, param_grid=param_grid_rf, cv=k_fold, scoring='f1')\n",
    "grid_search_f1.fit(X_train, y_train)\n",
    "# Afficher les meilleurs paramètres et le score f1\n",
    "print(\"Best Parameters (f1):\", grid_search_f1.best_params_)\n",
    "model_f1 = grid_search_f1.best_estimator_\n",
    "\n",
    "y_pred = model_f1.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"Score F1 sur l'ensemble de test:\", f1)\n",
    "\n",
    "\n",
    "###GRID SEARCH POUR Accuracy###\n",
    "grid_search_acc = GridSearchCV(estimator=model_rf, param_grid=param_grid_rf, cv=k_fold, scoring='accuracy')\n",
    "grid_search_acc.fit(X_train, y_train)\n",
    "# Afficher les meilleurs paramètres et le score accuracy\n",
    "print(\"Best Parameters (Accuracy):\", grid_search_acc.best_params_)\n",
    "model_acc = grid_search_acc.best_estimator_\n",
    "\n",
    "y_pred = model_acc.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy sur l'ensemble de test:\", accuracy)\n",
    "\n",
    "###GRID SEARCH POUR Recall###\n",
    "grid_search_recall = GridSearchCV(estimator=model_rf, param_grid=param_grid_rf, cv=k_fold, scoring='recall')\n",
    "grid_search_recall.fit(X_train, y_train)\n",
    "# Afficher les meilleurs paramètres et le score recall\n",
    "print(\"Best Parameters (Recall):\", grid_search_recall.best_params_)\n",
    "model_recall = grid_search_recall.best_estimator_\n",
    "\n",
    "y_pred = model_recall.predict(X_test)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Recall sur l'ensemble de test:\", recall)\n",
    "\n",
    "###GRID SEARCH POUR Precision###\n",
    "grid_search_precision = GridSearchCV(estimator=model_rf, param_grid=param_grid_rf, cv=k_fold, scoring='precision')\n",
    "grid_search_precision.fit(X_train, y_train)\n",
    "# Afficher les meilleurs paramètres et le score precision\n",
    "print(\"Best Parameters (Precision):\", grid_search_precision.best_params_)\n",
    "model_precision = grid_search_precision.best_estimator_\n",
    "\n",
    "y_pred = model_precision.predict(X_test)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precision sur l'ensemble de test:\", precision)\n",
    "\n",
    "###GRID SEARCH POUR ROC AUC###\n",
    "grid_search_roc_auc = GridSearchCV(estimator=model_rf, param_grid=param_grid_rf, cv=k_fold, scoring='roc_auc')\n",
    "grid_search_roc_auc.fit(X_train, y_train)\n",
    "# Afficher les meilleurs paramètres et le score roc_auc\n",
    "print(\"Best Parameters (ROC AUC):\", grid_search_roc_auc.best_params_)\n",
    "model_roc_auc = grid_search_roc_auc.best_estimator_\n",
    "\n",
    "y_pred_proba = model_roc_auc.predict_proba(X_test)[:, 1]  # Probabilité de la classe positive\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"ROC AUC sur l'ensemble de test:\", roc_auc)\n",
    "#Le coefficient de détermination R² est une métrique utilisée pour évaluer les modèles de régression, mais il n'est pas applicable aux modèles de classification comme XGBoost actue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "# Pour le ML\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, learning_curve, validation_curve, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Charger le jeu de données\n",
    "path = \"/home/onyxia/work/statapp_sujet26/\"\n",
    "\n",
    "\n",
    "file_name = \"fichier_var_dummy.csv\"\n",
    "\n",
    "df = pd.read_csv(path+file_name, sep=',',low_memory=False)\n",
    "\n",
    "df['grav'] = df['grav'].replace({1:0,2:0,3:1,4:1})\n",
    "\n",
    "y = df['grav']\n",
    "X = df.drop(columns=['grav'])\n",
    "features = X.columns\n",
    "\n",
    "\n",
    "# Diviser les données en ensembles de formation et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Normaliser les données\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Définir les hyperparamètres à tester\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [350, 400, 450],\n",
    "    'max_depth': [30, 35, 40],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialiser le modèle Random Forest\n",
    "model_rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialiser StratifiedKFold\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialiser GridSearchCV avec le modèle, la grille de paramètres et StratifiedKFold\n",
    "grid_search_rf = GridSearchCV(estimator=model_rf, param_grid=param_grid_rf, cv=k_fold, scoring='f1')\n",
    "\n",
    "# Exécuter la recherche sur la grille\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Afficher les meilleurs paramètres et le meilleur score\n",
    "print(\"Meilleurs Paramètres:\", grid_search_rf.best_params_)\n",
    "print(\"Meilleur Score:\", grid_search_rf.best_score_)\n",
    "\n",
    "model_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "\n",
    "###GRID SEARCH POUR F1###\n",
    "grid_search_f1 = GridSearchCV(estimator=model_rf, param_grid=param_grid_rf, cv=k_fold, scoring='f1')\n",
    "grid_search_f1.fit(X_train, y_train)\n",
    "# Afficher les meilleurs paramètres et le score f1\n",
    "print(\"Best Parameters (f1):\", grid_search_f1.best_params_)\n",
    "model_f1 = grid_search_f1.best_estimator_\n",
    "\n",
    "y_pred = model_f1.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"Score F1 sur l'ensemble de test:\", f1)\n",
    "\n",
    "\n",
    "###GRID SEARCH POUR Accuracy###\n",
    "grid_search_acc = GridSearchCV(estimator=model_rf, param_grid=param_grid_rf, cv=k_fold, scoring='accuracy')\n",
    "grid_search_acc.fit(X_train, y_train)\n",
    "# Afficher les meilleurs paramètres et le score accuracy\n",
    "print(\"Best Parameters (Accuracy):\", grid_search_acc.best_params_)\n",
    "model_acc = grid_search_acc.best_estimator_\n",
    "\n",
    "y_pred = model_acc.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy sur l'ensemble de test:\", accuracy)\n",
    "\n",
    "###GRID SEARCH POUR Recall###\n",
    "grid_search_recall = GridSearchCV(estimator=model_rf, param_grid=param_grid_rf, cv=k_fold, scoring='recall')\n",
    "grid_search_recall.fit(X_train, y_train)\n",
    "# Afficher les meilleurs paramètres et le score recall\n",
    "print(\"Best Parameters (Recall):\", grid_search_recall.best_params_)\n",
    "model_recall = grid_search_recall.best_estimator_\n",
    "\n",
    "y_pred = model_recall.predict(X_test)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Recall sur l'ensemble de test:\", recall)\n",
    "\n",
    "###GRID SEARCH POUR Precision###\n",
    "grid_search_precision = GridSearchCV(estimator=model_rf, param_grid=param_grid_rf, cv=k_fold, scoring='precision')\n",
    "grid_search_precision.fit(X_train, y_train)\n",
    "# Afficher les meilleurs paramètres et le score precision\n",
    "print(\"Best Parameters (Precision):\", grid_search_precision.best_params_)\n",
    "model_precision = grid_search_precision.best_estimator_\n",
    "\n",
    "y_pred = model_precision.predict(X_test)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precision sur l'ensemble de test:\", precision)\n",
    "\n",
    "###GRID SEARCH POUR ROC AUC###\n",
    "grid_search_roc_auc = GridSearchCV(estimator=model_rf, param_grid=param_grid_rf, cv=k_fold, scoring='roc_auc')\n",
    "grid_search_roc_auc.fit(X_train, y_train)\n",
    "# Afficher les meilleurs paramètres et le score roc_auc\n",
    "print(\"Best Parameters (ROC AUC):\", grid_search_roc_auc.best_params_)\n",
    "model_roc_auc = grid_search_roc_auc.best_estimator_\n",
    "\n",
    "y_pred_proba = model_roc_auc.predict_proba(X_test)[:, 1]  # Probabilité de la classe positive\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"ROC AUC sur l'ensemble de test:\", roc_auc)\n",
    "#Le coefficient de détermination R² est une métrique utilisée pour évaluer les modèles de régression, mais il n'est pas applicable aux modèles de classification comme XGBoost actue\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
