{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-optimize\n",
      "  Downloading scikit_optimize-0.10.1-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/mamba/lib/python3.12/site-packages (from scikit-optimize) (1.4.0)\n",
      "Collecting pyaml>=16.9 (from scikit-optimize)\n",
      "  Downloading pyaml-24.4.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /opt/mamba/lib/python3.12/site-packages (from scikit-optimize) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/mamba/lib/python3.12/site-packages (from scikit-optimize) (1.13.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /opt/mamba/lib/python3.12/site-packages (from scikit-optimize) (1.4.2)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/mamba/lib/python3.12/site-packages (from scikit-optimize) (24.0)\n",
      "Requirement already satisfied: PyYAML in /opt/mamba/lib/python3.12/site-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/mamba/lib/python3.12/site-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.4.0)\n",
      "Downloading scikit_optimize-0.10.1-py2.py3-none-any.whl (107 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyaml-24.4.0-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: pyaml, scikit-optimize\n",
      "Successfully installed pyaml-24.4.0 scikit-optimize-0.10.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (f1): {'colsample_bytree': 0.8, 'max_depth': 25, 'n_estimators': 200, 'subsample': 0.9}\n",
      "Score F1 sur l'ensemble de test: 0.8713357046485956\n",
      "Best Parameters (Accuracy): {'colsample_bytree': 0.8, 'max_depth': 25, 'n_estimators': 200, 'subsample': 0.9}\n",
      "Accuracy sur l'ensemble de test: 0.9108599592114208\n",
      "Best Parameters (Recall): {'colsample_bytree': 0.7, 'max_depth': 25, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Recall sur l'ensemble de test: 0.8592023065833734\n",
      "Best Parameters (Precision): {'colsample_bytree': 0.7, 'max_depth': 25, 'n_estimators': 100, 'subsample': 0.9}\n",
      "Precision sur l'ensemble de test: 0.8884442221110556\n",
      "Best Parameters (ROC AUC): {'colsample_bytree': 0.8, 'max_depth': 25, 'n_estimators': 200, 'subsample': 0.9}\n",
      "ROC AUC sur l'ensemble de test: 0.9542412297987262\n"
     ]
    }
   ],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "# Pour le ML\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, learning_curve, validation_curve, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Charger le jeu de données\n",
    "path = \"/home/onyxia/work/statapp_sujet26/\"\n",
    "\n",
    "file_name1 = \"dataset_complet_avec_dummies_part_1.csv\"\n",
    "file_name2 = \"dataset_complet_avec_dummies_part_2.csv\"\n",
    "file_name3 = \"dataset_complet_avec_dummies_part_3.csv\"\n",
    "file_name4 = \"dataset_complet_avec_dummies_part_4.csv\"\n",
    "df1 = pd.read_csv(path+file_name1, sep=',',low_memory=False)\n",
    "df2 = pd.read_csv(path+file_name2, sep=',',low_memory=False)\n",
    "df3 = pd.read_csv(path+file_name2, sep=',',low_memory=False)\n",
    "df4 = pd.read_csv(path+file_name2, sep=',',low_memory=False)\n",
    "df = pd.concat([df1,df2,df3,df4])\n",
    "\n",
    "\n",
    "df['grav'] = df['grav'].replace({1:0,2:0,3:1,4:1})\n",
    "\n",
    "y = df['grav']\n",
    "X = df.drop(columns=['grav'])\n",
    "features = X.columns\n",
    "\n",
    "\n",
    "# Diviser les données en ensembles de formation et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Normaliser les données\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Définir une grille de paramètres à rechercher\n",
    "param_grid = {\n",
    "    'max_depth': [5, 15, 25],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'n_estimators': [20, 100, 200],\n",
    "}\n",
    "\n",
    "model = xgb.XGBClassifier(objective='binary:logistic', random_state=42)\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "###GRID SEARCH POUR F1###\n",
    "grid_search_f1 = GridSearchCV(estimator=model, param_grid=param_grid, cv=k_fold, scoring='f1')\n",
    "grid_search_f1.fit(X_train, y_train)\n",
    "# Afficher les meilleurs paramètres et le score f1\n",
    "print(\"Best Parameters (f1):\", grid_search_f1.best_params_)\n",
    "model_f1 = grid_search_f1.best_estimator_\n",
    "\n",
    "y_pred = model_f1.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"Score F1 sur l'ensemble de test:\", f1)\n",
    "\n",
    "\n",
    "###GRID SEARCH POUR Accuracy###\n",
    "grid_search_acc = GridSearchCV(estimator=model, param_grid=param_grid, cv=k_fold, scoring='accuracy')\n",
    "grid_search_acc.fit(X_train, y_train)\n",
    "# Afficher les meilleurs paramètres et le score accuracy\n",
    "print(\"Best Parameters (Accuracy):\", grid_search_acc.best_params_)\n",
    "model_acc = grid_search_acc.best_estimator_\n",
    "\n",
    "y_pred = model_acc.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy sur l'ensemble de test:\", accuracy)\n",
    "\n",
    "###GRID SEARCH POUR Recall###\n",
    "grid_search_recall = GridSearchCV(estimator=model, param_grid=param_grid, cv=k_fold, scoring='recall')\n",
    "grid_search_recall.fit(X_train, y_train)\n",
    "# Afficher les meilleurs paramètres et le score recall\n",
    "print(\"Best Parameters (Recall):\", grid_search_recall.best_params_)\n",
    "model_recall = grid_search_recall.best_estimator_\n",
    "\n",
    "y_pred = model_recall.predict(X_test)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Recall sur l'ensemble de test:\", recall)\n",
    "\n",
    "###GRID SEARCH POUR Precision###\n",
    "grid_search_precision = GridSearchCV(estimator=model, param_grid=param_grid, cv=k_fold, scoring='precision')\n",
    "grid_search_precision.fit(X_train, y_train)\n",
    "# Afficher les meilleurs paramètres et le score precision\n",
    "print(\"Best Parameters (Precision):\", grid_search_precision.best_params_)\n",
    "model_precision = grid_search_precision.best_estimator_\n",
    "\n",
    "y_pred = model_precision.predict(X_test)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precision sur l'ensemble de test:\", precision)\n",
    "\n",
    "###GRID SEARCH POUR ROC AUC###\n",
    "grid_search_roc_auc = GridSearchCV(estimator=model, param_grid=param_grid, cv=k_fold, scoring='roc_auc')\n",
    "grid_search_roc_auc.fit(X_train, y_train)\n",
    "# Afficher les meilleurs paramètres et le score roc_auc\n",
    "print(\"Best Parameters (ROC AUC):\", grid_search_roc_auc.best_params_)\n",
    "model_roc_auc = grid_search_roc_auc.best_estimator_\n",
    "\n",
    "y_pred_proba = model_roc_auc.predict_proba(X_test)[:, 1]  # Probabilité de la classe positive\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"ROC AUC sur l'ensemble de test:\", roc_auc)\n",
    "#Le coefficient de détermination R² est une métrique utilisée pour évaluer les modèles de régression, mais il n'est pas applicable aux modèles de classification comme XGBoost actue\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
